{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "#All Required Libraries\n",
    "import math\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.color_palette(\"bright\")\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn  import functional as F \n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "\n",
    "use_cuda = torch.cuda.is_available() #Check if it is possible to use GPU.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchdiffeq import odeint_adjoint as odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser('ODE demo')\n",
    "parser.add_argument('--method', type=str, choices=['dopri5', 'adams'], default='dopri5')\n",
    "parser.add_argument('--data_size', type=int, default=1000)\n",
    "parser.add_argument('--batch_time', type=int, default=10)\n",
    "parser.add_argument('--batch_size', type=int, default=20)\n",
    "parser.add_argument('--niters', type=int, default=2000)\n",
    "parser.add_argument('--test_freq', type=int, default=20)\n",
    "parser.add_argument('--viz', action='store_true')\n",
    "parser.add_argument('--gpu', type=int, default=0)\n",
    "parser.add_argument('--adjoint', action='store_true')\n",
    "args = parser.parse_args()\n",
    "\n",
    "device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "true_y0 = torch.tensor([[2., 0.]]).to(device)\n",
    "t = torch.linspace(0., 25., args.data_size).to(device)\n",
    "true_A = torch.tensor([[-0.1, 2.0], [-2.0, -0.1]]).to(device)\n",
    "\n",
    "#Calculates Forward Pass and Gradients of the Loss function wrt z,t,parameters.\n",
    "#Compute f and a df/dz, a df/dp, a df/dt (i.e., da(t)/dt)\n",
    "class ODEF(nn.Module):\n",
    "    def forward_with_grad(self, z, t, grad_outputs):\n",
    "        batch_size = z.shape[0]\n",
    "\n",
    "        out = self.forward(z, t) #Calculates the forward pass of the model.\n",
    "\n",
    "        a = grad_outputs #Gradient of the model's output (out) wrt z, t, and all the model parameters.\n",
    "        adfdz, adfdt, *adfdp = torch.autograd.grad(\n",
    "            (out,), (z, t) + tuple(self.parameters()), grad_outputs=(a),\n",
    "            allow_unused=True, retain_graph=True\n",
    "        )\n",
    "        # grad method automatically sums gradients for batch items, we have to expand them back \n",
    "        if adfdp is not None:\n",
    "            adfdp = torch.cat([p_grad.flatten() for p_grad in adfdp]).unsqueeze(0) #Creates a list of flattened parameter gradients.\n",
    "            adfdp = adfdp.expand(batch_size, -1) / batch_size #Create the gradient tensor for each batchsize, second dim is unchanged (i.e., 1 for each parameter).\n",
    "        if adfdt is not None:\n",
    "            adfdt = adfdt.expand(batch_size, 1) / batch_size #Same as for the parameters but the second dimension is 1 as there is only 1 \"parameter\".\n",
    "        return out, adfdz, adfdt, adfdp\n",
    "\n",
    "    def flatten_parameters(self):\n",
    "        p_shapes = []\n",
    "        flat_parameters = []\n",
    "        for p in self.parameters():\n",
    "            p_shapes.append(p.size())\n",
    "            flat_parameters.append(p.flatten())\n",
    "        return torch.cat(flat_parameters)\n",
    "\n",
    "class GridODE(ODEF):\n",
    "    def __init__(self, M, D, B, G):\n",
    "        super(GridODE, self).__init__()\n",
    "        self.M = nn.Parameter(M)\n",
    "        self.D = nn.Parameter(D)\n",
    "        self.B = nn.Parameter(B)\n",
    "        self.G = nn.Parameter(G)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x_prime = x[:,1]\n",
    "        x_prime_prime = (-self.D * x_prime + self.B * torch.sin(x[:, 0]) - self.G * torch.cos(x[:, 0])) / self.M\n",
    "        x_prime_prime = x_prime_prime.view(-1)\n",
    "        return torch.stack((x_prime, x_prime_prime), dim=1)\n",
    "    \n",
    "class Lambda(nn.Module):\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        return torch.mm(y**3, true_A)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    true_y = odeint(Lambda(), true_y0, t, method='dopri5')\n",
    "\n",
    "\n",
    "def get_batch():\n",
    "    s = torch.from_numpy(np.random.choice(np.arange(args.data_size - args.batch_time, dtype=np.int64), args.batch_size, replace=False))\n",
    "    batch_y0 = true_y[s]  # (M, D)\n",
    "    batch_t = t[:args.batch_time]  # (T)\n",
    "    batch_y = torch.stack([true_y[s + i] for i in range(args.batch_time)], dim=0)  # (T, M, D)\n",
    "    return batch_y0.to(device), batch_t.to(device), batch_y.to(device)\n",
    "\n",
    "class ODEFunc(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ODEFunc, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 2),\n",
    "        )\n",
    "\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        return self.net(y**3)\n",
    "\n",
    "\n",
    "class RunningAverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, momentum=0.99):\n",
    "        self.momentum = momentum\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = None\n",
    "        self.avg = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        if self.val is None:\n",
    "            self.avg = val\n",
    "        else:\n",
    "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
    "        self.val = val"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
