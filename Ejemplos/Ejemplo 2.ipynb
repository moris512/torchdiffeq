{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import tqdm.notebook as tqdm\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Fixed Step Size Solver (Euler Method)\n",
    "def euler(func, t, dt, y):\n",
    "    return dt*func(t, y)\n",
    "\n",
    "#Adaptive Step Size Solver (Runge-Kutta Method)\n",
    "def rk4(func, t, dt, y):\n",
    "    k1 = func(t,y)\n",
    "    k2 = func(t + dt/2, y + dt/2 * k1)\n",
    "    k3 = func(t + dt/2, y + dt/2 * k2)\n",
    "    k4 = func(t + dt/2, y +dt*k3)\n",
    "    return dt/6*(k1 + 2*k2 + 2*k3 + k4)\n",
    "\n",
    "#Neural ODE\n",
    "class NeuralODE(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        \n",
    "    def forward(self, y0, t, solver):\n",
    "        solution = torch.empty(len(t), *y0.shape, dtype = y0.dtype, device = y0.device)\n",
    "        solution[0] = y0\n",
    "        j = 1\n",
    "        for t0, t1 in zip(t[:-1], t[1:]):\n",
    "            dy = solver(self.func, t0, t1-t0, y0)\n",
    "            y1 = y0 + dy\n",
    "            solution[j] = y1\n",
    "            j += 1\n",
    "            y0 = y1\n",
    "        return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment\n",
    "\n",
    "ode_test = NeuralODE(func = cos())\n",
    "test_result = ode_test(y0 = y0, t = t, solver = euler)\n",
    "print(test_result.size())\n",
    "test_result = test_result.transpose(0,1)\n",
    "print(test_result.size())\n",
    "test_result2 = ode_test(y0 = y0, t = t, solver = rk4)\n",
    "test_result2 = test_result2.transpose(0,1)\n",
    "\n",
    "#Visualize\n",
    "plt.plot(t.numpy(), test_result[0].detach().numpy(), label = 'euler', color = 'blue')\n",
    "plt.plot(t.numpy(), test_result2[0].detach().numpy(), label = 'rk4', color = 'red', linestyle = '--' )\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('y(t)')\n",
    "plt.title('Neural ODE')\n",
    "plt.grid(True)\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment 2 - Spiral Data Set\n",
    "\n",
    "data_size = 2000\n",
    "\n",
    "#generate data\n",
    "\n",
    "true_y0 = torch.tensor([[2., 0.]])\n",
    "t = torch.linspace(0., 25., data_size)\n",
    "true_A = torch.tensor([[-0.1, 2.0], [-2.0, -0.1]])\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "    def forward(self, t, y):\n",
    "        return torch.mm(y**3, true_A)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    node = NeuralODE(func = Lambda())\n",
    "    true_y = node(y0 = true_y0, t = t, solver = euler)\n",
    "    \n",
    "def visualize(true_y, pred_y = None):\n",
    "    fig = plt.figure(figsize = (6,6), facecolor='white')\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.set_title('Phase Portrait')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.plot(true_y.numpy()[:,0,0], true_y.numpy()[:,0,1], color = 'green', label = 'True Trajectory')\n",
    "    ax.scatter(true_y.numpy()[:,0,0], true_y.numpy()[:,0,1], color = 'blue', label = 'Sampled Data', s = 1)\n",
    "    if pred_y is not None:\n",
    "            ax.plot(pred_y.numpy()[:,0,0], pred_y.numpy()[:,0,1], color = 'red', label = 'Predicted Trajectory')\n",
    "    ax.set_xlim(-2.5, 2.5)\n",
    "    ax.set_ylim(-2.5, 2.5)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show\n",
    "        \n",
    "visualize(true_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mini Batch\n",
    "\n",
    "batch_time = 10\n",
    "batch_size = 16\n",
    "\n",
    "def get_batch():\n",
    "    s = torch.from_numpy(np.random.choice(np.arange(data_size - batch_time, dtype= np.int64), batch_size, replace=False))\n",
    "    batch_y0 = true_y[s] #Initial value of the batch\n",
    "    batch_t = t[:batch_time] #Time for the batch\n",
    "    batch_y = torch.stack([true_y[s + i] for i in range(batch_time)], dim = 0)\n",
    "    return batch_y0, batch_t, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural ODE\n",
    "class ODEFunc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(2,50), nn.Tanh(), nn.Linear(50,2)) #y0 is a 2D tensor\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean = 0, std = 0.1)\n",
    "                nn. init.constant_(m.bias, val = 0)\n",
    "                \n",
    "    def forward(self, t, y):\n",
    "        output = self.net(y**3) #I know this is the structure of the ODE\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train NODE\n",
    "niters = 400\n",
    "\n",
    "node = NeuralODE(func = ODEFunc())\n",
    "optimizer = optim.RMSprop(node.parameters(), lr=1e-3)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for iter in tqdm.tqdm(range(niters + 1)):\n",
    "    optimizer.zero_grad()\n",
    "    batch_y0, batch_t, batch_y = get_batch()\n",
    "    pred_y = node(y0 = batch_y0, t = batch_t, solver = rk4)\n",
    "    loss = torch.mean(torch.abs(pred_y - batch_y))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if iter % 50 == 0: #For every 50 step we check the process\n",
    "        with torch.no_grad():\n",
    "            pred_y = node(true_y0, t, solver = rk4)\n",
    "            loss = torch.mean(torch.abs(pred_y - true_y))\n",
    "            print('Iteration {:04d} | Total Loss {:.6f}'.format(iter, loss.item()))\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            fig = plt.figure(figsize=(10, 10), facecolor='white')\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "            ax.set_title('Phase Portrait')\n",
    "            ax.set_xlabel('x')\n",
    "            ax.set_ylabel('y')\n",
    "            ax.set_xlim(-2.5, 2.5)\n",
    "            ax.set_ylim(-2.5, 2.5)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            visualize(true_y, pred_y)\n",
    "        \n",
    "end_time = time.time() - start_time\n",
    "print('process time: {} sec'.format(end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Adaptive Solvers - The torchdiffeq\n",
    "\n",
    "from torchdiffeq import odeint\n",
    "#odeint(func, y0, t, rtol, atol, method)\n",
    "ninters = 400\n",
    "\n",
    "func = ODEFunc()\n",
    "optimizer = optim.RMSprop(func.parameters(), lr = 1e-3)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for iter in tqdm.tqdm(range(ninters + 1)):\n",
    "    optimizer.zero_grad()\n",
    "    batch_y0, batch_t, batch_y = get_batch()\n",
    "    pred_y = odeint(func = func, y0 = batch_y0, t = batch_t, rtol = 1e-7, atol = 1e-9, method = 'dopri5')\n",
    "    loss = torch.mean(torch.abs(pred_y - batch_y))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iter % 50 == 0: #For every 50 step we check the process\n",
    "        with torch.no_grad():\n",
    "            pred_y = odeint(func, true_y0, t, rtol = 1e-7, atol = 1e-9, method = 'dopri5')\n",
    "            loss = torch.mean(torch.abs(pred_y - true_y))\n",
    "            print('Iteration {:04d} | Total Loss {:.6f}'.format(iter, loss.item()))\n",
    "            visualize(true_y, pred_y)\n",
    "        \n",
    "end_time = time.time() - start_time\n",
    "print('process time: {} sec'.format(end_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjoint Backpropagation Method\n",
    "\n",
    "from torchdiffeq import odeint_adjoint\n",
    "ninters = 400\n",
    "\n",
    "func = ODEFunc()\n",
    "optimizer = optim.RMSprop(func.parameters(), lr = 1e-3)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for iter in tqdm.tqdm(range(ninters + 1)):\n",
    "    optimizer.zero_grad()\n",
    "    batch_y0, batch_t, batch_y = get_batch()\n",
    "    pred_y = odeint_adjoint(func = func, y0 = batch_y0, t = batch_t, rtol = 1e-7, atol = 1e-9, method = 'dopri5')\n",
    "    loss = torch.mean(torch.abs(pred_y - batch_y))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iter % 50 == 0: #For every 50 step we check the process\n",
    "        with torch.no_grad():\n",
    "            pred_y = odeint_adjoint(func, true_y0, t, rtol=1e-7, atol=1e-9, method='dopri5')\n",
    "            loss = torch.mean(torch.abs(pred_y - true_y))\n",
    "            print('Iteration {:04d} | Total Loss {:.6f}'.format(iter, loss.item()))\n",
    "            visualize(true_y, pred_y)\n",
    "        \n",
    "end_time = time.time() - start_time\n",
    "print('process time: {} sec'.format(end_time))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
