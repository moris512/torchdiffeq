{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All Required Libraries\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.color_palette(\"bright\")\n",
    "import matplotlib.cm as cm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchdiffeq import odeint_adjoint as odeint #Otherwise only \"odeint_adjoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration\n",
    "method = 'rk4' #RK-45\n",
    "data_size = 600 #300 every 10 seconds\n",
    "batch_time = 30\n",
    "batch_size = 20\n",
    "niters = 5000\n",
    "test_freq = 20\n",
    "viz = True\n",
    "gpu = 0\n",
    "#device = torch.device('cuda:' + str(gpu) if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Real ODE System\n",
    "omega0 = torch.tensor(2*60*np.pi)\n",
    "delta1star = -0.117919635325941\n",
    "omega1star = 0\n",
    "delta2star = 0.094729837775605\n",
    "omega2star = 0\n",
    "v1star = torch.tensor(2.04379374735951)\n",
    "v2star = torch.tensor(1.98829642487374)\n",
    "x0 = torch.tensor([[delta1star + np.pi/6], [omega1star], [delta2star], [omega2star]]).to(device)\n",
    "t = torch.arange(0.,20., 1/30).to(device)\n",
    "\n",
    "M1 = torch.tensor(100)\n",
    "D1 = torch.tensor(10)\n",
    "X1 = torch.tensor(0.963)\n",
    "M2 = torch.tensor(12)\n",
    "D2 = torch.tensor(10)\n",
    "X2 = torch.tensor(0.667)\n",
    "Bred = torch.tensor(-0.583070554936976)\n",
    "Gred = torch.tensor(-0.003399828308670)\n",
    "Pmech1star = torch.tensor(-0.513568531598284)\n",
    "Pmech2star = torch.tensor(0.486559381709619)\n",
    "#Pmech1star = torch.tensor(-v1star*v2star*Bred*np.sin(delta1star - delta2star) + v1star*v2star*Gred*np.cos(delta1star-delta2star))\n",
    "#Pmech2star = torch.tensor(-v1star*v2star*Bred*np.sin(delta2star - delta1star) + v1star*v2star*Gred*np.cos(delta2star-delta1star))\n",
    "\n",
    "\n",
    "class Real(nn.Module):\n",
    "    def forward(self,t,x):\n",
    "        dxdt = torch.zeros_like(x)\n",
    "        dxdt[0] = x[1]\n",
    "        dxdt[1] = (-D1*x[1]/omega0 + v1star*v2star*Bred*torch.sin(x[0]-x[2]) - v1star*v2star*Gred*torch.cos(x[0]-x[2]) + Pmech1star)*omega0/M1\n",
    "        dxdt[2] = x[3]\n",
    "        dxdt[3] = (-D2*x[3]/omega0 + v1star*v2star*Bred*torch.sin(x[2]-x[0]) - v1star*v2star*Gred*torch.cos(x[2]-x[0]) + Pmech2star)*omega0/M2\n",
    "        self.dxdt = dxdt\n",
    "        return dxdt\n",
    "\n",
    "real_dynamics = Real()  \n",
    "  \n",
    "with torch.no_grad():\n",
    "    true_x = odeint(real_dynamics, x0, t, method = method)\n",
    "\n",
    "true_omega1 = true_x[:,1,0] / omega0\n",
    "true_omega2 = true_x[:,3,0] / omega0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Correct Data\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(t.cpu().numpy(), true_omega1.cpu().numpy(), label=r'$\\omega_1$')\n",
    "plt.plot(t.cpu().numpy(), true_omega2.cpu().numpy(), label=r'$\\omega_2$')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency Deviation [p.u.]')\n",
    "plt.title('Real Solution')\n",
    "plt.legend(fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Mini-Batches\n",
    "def get_batch():\n",
    "    s = torch.from_numpy(np.random.choice(np.arange(data_size - batch_time, dtype=np.int64), batch_size, replace=False))\n",
    "    batch_x0 = true_x[s]\n",
    "    batch_t = t[:batch_time]\n",
    "    batch_x = torch.stack([true_x[s + i] for i in range(batch_time)], dim=0)\n",
    "    return s.to(device), batch_x0.to(device), batch_t.to(device), batch_x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization\n",
    "\n",
    "def visualize(true_x, pred_x, t, omega0, viz, save_path):\n",
    "    if viz:\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        \n",
    "        #Generator 1 - Rotor Angle and Frequency Deviation\n",
    "        axs[0, 0].set_title('Generator 1 - Rotor Angle')\n",
    "        axs[0, 0].set_xlabel('Time [s]')\n",
    "        axs[0, 0].set_ylabel('Rotor Angle [p.u,]')\n",
    "        axs[0, 0].plot(t.cpu().numpy(), true_x[:,0,0].cpu().numpy(), label=r'True $\\delta_1$')\n",
    "        axs[0, 0].plot(t.cpu().numpy(), pred_x[:,0,0].cpu().numpy(), '--', label=r'Predicted $\\delta_1$')\n",
    "        axs[0, 0].legend(fontsize=14)\n",
    "        \n",
    "        axs[0, 1].set_title('Generator 1 - Frequency Deviation')\n",
    "        axs[0, 1].set_xlabel('Time [s]')\n",
    "        axs[0, 1].set_ylabel('Frequency Deviation [p.u.]')\n",
    "        axs[0, 1].plot(t.cpu().numpy(), true_x[:,1,0].cpu().numpy()/omega0, label=r'True $\\omega_1$')\n",
    "        axs[0, 1].plot(t.cpu().numpy(), pred_x[:,1,0].cpu().numpy()/omega0, '--', label=r'Predicted $\\omega_1$')\n",
    "        axs[0, 1].legend(fontsize=14)\n",
    "        \n",
    "        #Generator 2 - Rotor Angle and Frequency Deviation\n",
    "        axs[1, 0].set_title('Generator 2 - Rotor Angle')\n",
    "        axs[1, 0].set_xlabel('Time [s]')\n",
    "        axs[1, 0].set_ylabel('Rotor Angle [p.u,]')\n",
    "        axs[1, 0].plot(t.cpu().numpy(), true_x[:,2,0].cpu().numpy(), label=r'True $\\delta_2$')\n",
    "        axs[1, 0].plot(t.cpu().numpy(), pred_x[:,2,0].cpu().numpy(), '--', label=r'Predicted $\\delta_2$')\n",
    "        axs[1, 0].legend(fontsize=14)\n",
    "        \n",
    "        axs[1, 1].set_title('Generator 2 - Frequency Deviation')\n",
    "        axs[1, 1].set_xlabel('Time [s]')\n",
    "        axs[1, 1].set_ylabel('Frequency Deviation [p.u.]')\n",
    "        axs[1, 1].plot(t.cpu().numpy(), true_x[:,3,0].cpu().numpy()/omega0, label=r'True $\\omega_2$')\n",
    "        axs[1, 1].plot(t.cpu().numpy(), pred_x[:,3,0].cpu().numpy()/omega0, '--', label=r'Predicted $\\omega_2$')\n",
    "        axs[1, 1].legend(fontsize=14)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        plt.savefig(save_path)\n",
    "        plt.show()\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN to learn the ODE\n",
    "\n",
    "class NeuralODE(nn.Module):\n",
    "    def __init__(self, M1, D1, M2, D2, V1, V2, B, G, Pmech1, Pmech2):\n",
    "        super(NeuralODE, self).__init__()\n",
    "        self.M1 = M1\n",
    "        self.M2 = nn.Parameter(M2)\n",
    "        self.D1 = D1\n",
    "        self.D2 = nn.Parameter(D2)\n",
    "        self.V1 = V1\n",
    "        #self.V2 = V2\n",
    "        self.V2 = nn.Parameter(V2)\n",
    "        #self.B = B\n",
    "        self.B = nn.Parameter(B)\n",
    "        #self.G = G\n",
    "        self.G = nn.Parameter(G)\n",
    "        self.Pmech1 = Pmech1\n",
    "        #self.Pmech2 = Pmech2\n",
    "        self.Pmech2 = nn.Parameter(Pmech2)\n",
    "        \n",
    "    def forward(self, t, y):\n",
    "        dydt = torch.zeros_like(y)\n",
    "        dydt[0] = y[1]\n",
    "        dydt[1] = (-self.D1*y[1]/omega0 + self.V1*self.V2*self.B*torch.sin(y[0]-y[2]) - self.V1*self.V2*self.G*torch.cos(y[0]-y[2]) + self.Pmech1)*omega0/self.M1\n",
    "        dydt[2] = y[3]\n",
    "        dydt[3] = (-self.D2*y[3]/omega0 + self.V1*self.V2*self.B*torch.sin(y[2]-y[0]) - self.V1*self.V2*self.G*torch.cos(y[2]-y[0]) + self.Pmech2)*omega0/self.M2\n",
    "        self.dydt = dydt\n",
    "        return dydt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Learnable Parameters\n",
    "Delta = 0.01 #Porcentual deviation from real value\n",
    "#TargetPercent = 0.01\n",
    "Treshold = 1e-11 #1e-7\n",
    "M1_G = M1\n",
    "D1_G = D1\n",
    "M2_G = Delta*M2\n",
    "D2_G = Delta*D2\n",
    "V1_G = v1star\n",
    "#V2_G = v2star\n",
    "V2_G = Delta*v2star\n",
    "#B_G = Bred\n",
    "B_G = Delta*Bred\n",
    "#G_G = Gred\n",
    "G_G = Delta*Gred\n",
    "Pmech1_G = Pmech1star\n",
    "#Pmech2_G = Pmech2star\n",
    "Pmech2_G = Delta*Pmech2star\n",
    "\n",
    "func = NeuralODE(M1_G, D1_G, M2_G, D2_G, V1_G, V2_G, B_G, G_G, Pmech1_G, Pmech2_G).to(device)\n",
    "\n",
    "\n",
    "for name, param in func.named_parameters():\n",
    "    print(f\"Name: {name}, Shape: {param.size()}, Requires Grad: {param.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loop - Mac - MDV\n",
    "Delta = 1.05 #Porcentual deviation from real value\n",
    "#TargetPercent = 0.01\n",
    "Treshold = 1e-11 #1e-13 for [MD, MDV], 1e-11 for [MDVP, MDVPBG]\n",
    "M1_G = M1\n",
    "D1_G = D1\n",
    "M2_G = Delta*M2\n",
    "D2_G = Delta*D2\n",
    "V1_G = v1star\n",
    "#V2_G = v2star\n",
    "V2_G = Delta*v2star\n",
    "#B_G = Bred\n",
    "B_G = Delta*Bred\n",
    "#G_G = Gred\n",
    "G_G = Delta*Gred\n",
    "Pmech1_G = Pmech1star\n",
    "#Pmech2_G = Pmech2star\n",
    "Pmech2_G = Delta*Pmech2star\n",
    "\n",
    "parameters_correct = [M1,D1,M2,D2,v1star,v2star,Bred,Gred,Pmech1star,Pmech2star]\n",
    "parameters_data = []\n",
    "\n",
    "\n",
    "csv_file_path = \"MDVPBG/Data.csv\"\n",
    "plot_save_path = \"MDVPBG/Initial.png\"\n",
    "\n",
    "os.makedirs(os.path.dirname(csv_file_path), exist_ok=True)\n",
    "\n",
    "\n",
    "print(f\"M1: {M1.item()}\", f\"M1_G: {M1_G.item()}\")\n",
    "print(f\"D1: {D1.item()}\", f\"D1_G: {D1_G.item()}\")\n",
    "print(f\"M2: {M2.item()}\", f\"M2_G: {M2_G.item()}\")\n",
    "print(f\"D2: {D2.item()}\", f\"D2_G: {D2_G.item()}\")\n",
    "print(f\"V1: {v1star.item()}\", f\"V1_G: {V1_G.item()}\")\n",
    "print(f\"V2: {v2star.item()}\", f\"V2_G: {V2_G.item()}\")\n",
    "print(f\"Bred: {Bred.item()}\", f\"B_G: {B_G.item()}\")\n",
    "print(f\"Gred: {Gred.item()}\", f\"G_G: {G_G.item()}\")\n",
    "print(f\"Pmech1: {Pmech1star.item()}\", f\"Pmech1_G: {Pmech1_G.item()}\")\n",
    "print(f\"Pmech2: {Pmech2star.item()}\", f\"Pmech2_G: {Pmech2_G.item()}\")\n",
    "\n",
    "func = NeuralODE(M1_G, D1_G, M2_G, D2_G, V1_G, V2_G, B_G, G_G, Pmech1_G, Pmech2_G).to(device)\n",
    "normal_lr = 0.001\n",
    "special_lr = 0.0001\n",
    "special_param = [func.Pmech2, func.B, func.G]\n",
    "other_param = [param for name, param in func.named_parameters() if param not in special_param]\n",
    "param_groups = [{'params': other_param, 'lr': normal_lr}, {'params': special_param, 'lr': special_lr}]\n",
    "optimizer = torch.optim.RMSprop(param_groups) #RMSprop\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 100, gamma=0.5, verbose=False)\n",
    "#scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.005, epochs=1000, steps_per_epoch=20)\n",
    "\n",
    "ii = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    print('Initial Parameters:')\n",
    "    for name, param in func.named_parameters():\n",
    "        print(f\"{name}: {param.data}\")\n",
    "    initial_pred = odeint(func,x0,t).to(device)\n",
    "    initial_true = true_x.to(device)\n",
    "    visualize(initial_true, initial_pred, t, omega0, viz, plot_save_path)\n",
    "\n",
    "grad_norm_values = []\n",
    "start_time = time.time()\n",
    "\n",
    "for itr in range(0, niters):\n",
    "    grad_norm = 0\n",
    "    optimizer.zero_grad()\n",
    "    s, batch_x0, batch_t, batch_x = get_batch()\n",
    "\n",
    "    for batch_n in range(0,batch_size):\n",
    "        low = int(s[batch_n])\n",
    "        high = low + batch_time\n",
    "        pred_x = odeint(func, batch_x0[batch_n], batch_t, method = method).to(device)\n",
    "        #loss = torch.mean((pred_x - batch_x[:,batch_n,:,:])**2) #loss using all states.\n",
    "        loss = torch.mean((pred_x[:,0:2,0] - batch_x[:,batch_n,0:2,0])**2) #loss using only delta1 and omega1.\n",
    "        loss.backward() #Calculate the dloss/dparameters\n",
    "        optimizer.step() #Update value of parameters\n",
    "        #scheduler.step() - For cyclic scheduler\n",
    "        #print(f'\\nBatch {batch_n:d} | Loss {loss.item():.20f}')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for name, param in func.named_parameters():\n",
    "                if name in ['M2', 'D2', 'V2', 'Pmech2']:\n",
    "                    param.clamp_(min=0.1) #make sure values are positive\n",
    "\n",
    "        for param in func.parameters():\n",
    "            if param.grad is not None:\n",
    "                grad_norm = param.grad.data.norm(2).item()**2\n",
    "        grad_norm = math.sqrt(grad_norm)\n",
    "        grad_norm_values.append(grad_norm)\n",
    "\n",
    "        current_parameters = [param.item() for name, param in func.named_parameters()]\n",
    "        iteration_time = time.time() - start_time\n",
    "        parameters_data.append([itr] + current_parameters + [loss.item(), iteration_time, grad_norm])\n",
    "\n",
    "    if itr % test_freq == 0:\n",
    "        with torch.no_grad():\n",
    "            pred_x = odeint(func, x0, t).to(device)\n",
    "            #loss = torch.mean((pred_x - true_x)**2) #Loss using all states.\n",
    "            loss = torch.mean((pred_x[:,0:2,0] - true_x[:,0:2,0])**2) #Loss using only delta1 and omega1.\n",
    "            print(f'\\nIteration {itr:d} | Total Loss {loss.item():.20f}')\n",
    "            print('Updated Parameters:')\n",
    "            for name, param in func.named_parameters():\n",
    "                print(f\"{name}: {param.data}\")\n",
    "            plot_save_path = f'MDVPBG/Iteration_{itr}.png'\n",
    "            visualize(true_x, pred_x, t, omega0, viz, plot_save_path)\n",
    "            \n",
    "            with open(csv_file_path, 'a', newline='') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                if itr == 0:\n",
    "                    header = ['Iteration'] + [name for name, _ in func.named_parameters()] + ['Loss', 'Time', 'Gradient Norm']\n",
    "                    writer.writerow(header)\n",
    "                writer.writerows(parameters_data)\n",
    "                parameters_data = []\n",
    "            ii += 1\n",
    "\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(grad_norm_values, label= 'Gradient Norm')\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.ylabel('Gradient Norm')\n",
    "            plt.title('Gradient Norm Evolution')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "    scheduler.step()\n",
    "    end = time.time()\n",
    "\n",
    "    #if grad_norm <= Treshold:\n",
    "    if loss <= Treshold:\n",
    "         print(f'Stopping at iteration {itr} as the value of the loss is below the threshold: {Treshold}')\n",
    "         print(f'Loss: {loss.item():.20f}')\n",
    "         print(f'M2_G: {func.M2.item():.20f}')\n",
    "         print(f'D2_G: {func.D2.item():.20f}')\n",
    "         print(f'V2_G: {func.V2.item():.20f}')\n",
    "         print(f'B_G: {func.B.item():.20f}')\n",
    "         print(f'G_G: {func.G.item():.20f}')\n",
    "         print(f'Pmech2_G: {func.Pmech2.item():.20f}')\n",
    "\n",
    "         with torch.no_grad():\n",
    "             pred_x = odeint(func, x0, t).to(device)\n",
    "             #loss = torch.mean((pred_x - true_x)**2) #Loss using all states.\n",
    "             loss = torch.mean((pred_x[:,0:2,0] - true_x[:,0:2,0])**2) #Loss using only delta1 and omega1.\n",
    "             print(f'\\nIteration {itr:d} | Total Loss {loss.item():.20f}')\n",
    "             print('Updated Parameters:')\n",
    "             for name, param in func.named_parameters():\n",
    "                 print(f\"{name}: {param.data}\")\n",
    "             plot_save_path = f'MDVPBG/Iteration_{itr}.png'\n",
    "             visualize(true_x, pred_x, t, omega0, viz, plot_save_path)\n",
    "             with open(csv_file_path, 'a', newline='') as csvfile:\n",
    "                 writer = csv.writer(csvfile)\n",
    "                 writer.writerows(parameters_data)\n",
    "         break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
